{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d387c190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb7ef544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps to Create a Random Forest\n",
    "# 1- Bagging: Randomly sample subsets of the data (with replacement) for each tree.\n",
    "# 2- For each tree, randomly select a subset of features at each split.\n",
    "# 3- Train a decision tree on each sampled dataset.\n",
    "# 4- Repeat steps 1â€“3 to build multiple decision trees.\n",
    "# 5- Aggregating: For predictions, aggregate the outputs of all the trees (e.g., majority vote for classification or averaging for regression).\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "class RandomForest:\n",
    "    \"\"\"\n",
    "    A random forest classifier for multi-class classification problems (using decision stumps with depth 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_trees=7):\n",
    "        self.n_trees = n_trees\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fits a random forest to the dataset (X, y).\n",
    "        \"\"\"\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            stump = DecisionStump()\n",
    "            X_sample, y_sample = self._bootstrap_samples(X, y)\n",
    "            stump.fit(X_sample, y_sample)\n",
    "            self.trees.append(stump)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts class labels for samples in X.\n",
    "        \"\"\"\n",
    "        stump_predictions = np.array([stump.predict(X) for stump in self.trees])\n",
    "        return self._majority_vote(stump_predictions)\n",
    "    \n",
    "    def _bootstrap_samples(self, X, y):\n",
    "        \"\"\"\n",
    "        Applies bootstrap resampling to the dataset.\n",
    "        \"\"\"\n",
    "        return resample(X, y, n_samples=len(X), replace=True)\n",
    "    \n",
    "    def _majority_vote(self, predictions):\n",
    "        \"\"\"\n",
    "        Returns the majority vote of the predictions.\n",
    "        \"\"\"\n",
    "        return np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "364004c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer features: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "Breast Cancer target: ['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "X, y = breast_cancer.data, breast_cancer.target\n",
    "\n",
    "print(f\"Breast Cancer features: {breast_cancer.feature_names}\")\n",
    "print(f\"Breast Cancer target: {breast_cancer.target_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2af9531a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (455, 30), y_train: (455,)\n",
      "Shape of X_test: (114, 30), y_test: (114,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ab472b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionStump:\n",
    "    def __init__(self):\n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "        self.polarity = None\n",
    "        self.alpha = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape\n",
    "        min_error = float('inf')\n",
    "        for feature_i in range(n):\n",
    "            feature_values = np.expand_dims(X[:, feature_i], axis=1)\n",
    "            unique_values = np.unique(feature_values)\n",
    "            for threshold in unique_values:\n",
    "                for polarity in [1, -1]:\n",
    "                    error = 0\n",
    "                    for i in range(m):\n",
    "                        prediction = polarity * (1 if X[i, feature_i] < threshold else -1)\n",
    "                        if prediction != y[i]:\n",
    "                            error += 1\n",
    "                    if error < min_error:\n",
    "                        min_error = error\n",
    "                        self.feature_index = feature_i\n",
    "                        self.threshold = threshold\n",
    "                        self.polarity = polarity\n",
    "\n",
    "    def predict(self, X):\n",
    "        m = X.shape[0]\n",
    "        predictions = np.ones(m)\n",
    "        for i in range(m):\n",
    "            predictions[i] = self.polarity * (1 if X[i, self.feature_index] < self.threshold else -1)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa826ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "def predict(self, X):\n",
    "    m = X.shape[0]\n",
    "    predictions = np.ones(m, dtype=int)  # Cast to int\n",
    "    for i in range(m):\n",
    "        predictions[i] = int(self.polarity * (1 if X[i, self.feature_index] < self.threshold else -1))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3505a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _majority_vote(self, predictions):\n",
    "    \"\"\"\n",
    "    Returns the majority vote of the predictions.\n",
    "    \"\"\"\n",
    "    predictions = predictions.astype(int)  # Force integer type\n",
    "    return np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b10dcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming y_train contains string labels\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)  # Converts labels to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f56141a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom RF Accuracy: 0.965\n",
      "Custom RF F1-Score: 0.965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming y_train contains string labels\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)  # Encode labels to integers\n",
    "\n",
    "rf_custom = RandomForestClassifier()\n",
    "rf_custom.fit(X_train, y_train_encoded)\n",
    "\n",
    "rf_cust_predictions = rf_custom.predict(X_test)\n",
    "\n",
    "print(f\"Custom RF Accuracy: {accuracy_score(y_test, rf_cust_predictions):.3f}\")\n",
    "print(f\"Custom RF F1-Score: {f1_score(y_test, rf_cust_predictions, average='weighted'):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aecee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
